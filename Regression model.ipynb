{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd13bb56",
   "metadata": {},
   "source": [
    "# Regression Model in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff8216b",
   "metadata": {},
   "source": [
    "#### In this project, we build a regression model using the deep learning Keras library, and then experiments with increasing the number of training epochs and changing number of hidden layers and will see how changing these parameters impacts the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ecc2e0",
   "metadata": {},
   "source": [
    "# A. Build a baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3757f2d",
   "metadata": {},
   "source": [
    "Use the Keras library to build a neural network with the following:\n",
    "\n",
    "- One hidden layer of 10 nodes, and a ReLU activation function\n",
    "\n",
    "- Use the adam optimizer and the mean squared error  as the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5815131",
   "metadata": {},
   "source": [
    "\n",
    "1. Randomly split the data into a training and test sets by holding 30% of the data for testing.Using the train_test_splithelper function from Scikit-learn.\n",
    "\n",
    "2. Train the model on the training data using 50 epochs.\n",
    "\n",
    "3. Evaluate the model on the test data and compute the mean squared error between the predicted concrete strength and the actual concrete strength. You can use the mean_squared_error function from Scikit-learn.\n",
    "\n",
    "4. Repeat steps 1 - 3, 50 times, i.e., create a list of 50 mean squared errors.\n",
    "\n",
    "5. Report the mean and the standard deviation of the mean squared errors.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fa1a82",
   "metadata": {},
   "source": [
    "Import the pandas, the numpy, the keras libraries and the packages from the keras library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "754f4fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "#import sklearn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59283f5c",
   "metadata": {},
   "source": [
    "#### Getting Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af90ad8f",
   "metadata": {},
   "source": [
    "The dataset is about the compressive strength of different samples of concrete based on the volumes of the different ingredients that were used to make them. Ingredients include:\n",
    "\n",
    "1. Cement\n",
    "\n",
    "2. Blast Furnace Slag\n",
    "\n",
    "3. Fly Ash\n",
    "\n",
    "4. Water\n",
    "\n",
    "5. Superplasticizer\n",
    "\n",
    "6. Coarse Aggregate\n",
    "\n",
    "7. Fine Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b6984c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>266.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>90</td>\n",
       "      <td>47.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>380.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>43.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>380.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>28</td>\n",
       "      <td>36.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>266.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>28</td>\n",
       "      <td>45.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>475.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>28</td>\n",
       "      <td>39.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "5   266.0               114.0      0.0  228.0               0.0   \n",
       "6   380.0                95.0      0.0  228.0               0.0   \n",
       "7   380.0                95.0      0.0  228.0               0.0   \n",
       "8   266.0               114.0      0.0  228.0               0.0   \n",
       "9   475.0                 0.0      0.0  228.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  \n",
       "5             932.0           670.0   90     47.03  \n",
       "6             932.0           594.0  365     43.70  \n",
       "7             932.0           594.0   28     36.45  \n",
       "8             932.0           670.0   28     45.85  \n",
       "9             932.0           594.0   28     39.29  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data = pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0101EN/labs/data/concrete_data.csv')\n",
    "concrete_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5986ce95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1030, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking how many  data points we have\n",
    "concrete_data.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a2b813",
   "metadata": {},
   "source": [
    "We have approx 1000 samples to train our model \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Checking for any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86cbb3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>281.167864</td>\n",
       "      <td>73.895825</td>\n",
       "      <td>54.188350</td>\n",
       "      <td>181.567282</td>\n",
       "      <td>6.204660</td>\n",
       "      <td>972.918932</td>\n",
       "      <td>773.580485</td>\n",
       "      <td>45.662136</td>\n",
       "      <td>35.817961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.506364</td>\n",
       "      <td>86.279342</td>\n",
       "      <td>63.997004</td>\n",
       "      <td>21.354219</td>\n",
       "      <td>5.973841</td>\n",
       "      <td>77.753954</td>\n",
       "      <td>80.175980</td>\n",
       "      <td>63.169912</td>\n",
       "      <td>16.705742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>121.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>192.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>164.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>932.000000</td>\n",
       "      <td>730.950000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>272.900000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>779.500000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>34.445000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>142.950000</td>\n",
       "      <td>118.300000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>1029.400000</td>\n",
       "      <td>824.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>46.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>540.000000</td>\n",
       "      <td>359.400000</td>\n",
       "      <td>200.100000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>32.200000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>992.600000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>82.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Cement  Blast Furnace Slag      Fly Ash        Water  \\\n",
       "count  1030.000000         1030.000000  1030.000000  1030.000000   \n",
       "mean    281.167864           73.895825    54.188350   181.567282   \n",
       "std     104.506364           86.279342    63.997004    21.354219   \n",
       "min     102.000000            0.000000     0.000000   121.800000   \n",
       "25%     192.375000            0.000000     0.000000   164.900000   \n",
       "50%     272.900000           22.000000     0.000000   185.000000   \n",
       "75%     350.000000          142.950000   118.300000   192.000000   \n",
       "max     540.000000          359.400000   200.100000   247.000000   \n",
       "\n",
       "       Superplasticizer  Coarse Aggregate  Fine Aggregate          Age  \\\n",
       "count       1030.000000       1030.000000     1030.000000  1030.000000   \n",
       "mean           6.204660        972.918932      773.580485    45.662136   \n",
       "std            5.973841         77.753954       80.175980    63.169912   \n",
       "min            0.000000        801.000000      594.000000     1.000000   \n",
       "25%            0.000000        932.000000      730.950000     7.000000   \n",
       "50%            6.400000        968.000000      779.500000    28.000000   \n",
       "75%           10.200000       1029.400000      824.000000    56.000000   \n",
       "max           32.200000       1145.000000      992.600000   365.000000   \n",
       "\n",
       "          Strength  \n",
       "count  1030.000000  \n",
       "mean     35.817961  \n",
       "std      16.705742  \n",
       "min       2.330000  \n",
       "25%      23.710000  \n",
       "50%      34.445000  \n",
       "75%      46.135000  \n",
       "max      82.600000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cfab169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cement                0\n",
       "Blast Furnace Slag    0\n",
       "Fly Ash               0\n",
       "Water                 0\n",
       "Superplasticizer      0\n",
       "Coarse Aggregate      0\n",
       "Fine Aggregate        0\n",
       "Age                   0\n",
       "Strength              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f23852",
   "metadata": {},
   "source": [
    "Now data looks clean and is ready to build our model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6faa111",
   "metadata": {},
   "source": [
    "#### Splitting Data into  predictors and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b7f53b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_data_columns = concrete_data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98807a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>266.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>380.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>380.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>266.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>475.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "5   266.0               114.0      0.0  228.0               0.0   \n",
       "6   380.0                95.0      0.0  228.0               0.0   \n",
       "7   380.0                95.0      0.0  228.0               0.0   \n",
       "8   266.0               114.0      0.0  228.0               0.0   \n",
       "9   475.0                 0.0      0.0  228.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  \n",
       "0            1040.0           676.0   28  \n",
       "1            1055.0           676.0   28  \n",
       "2             932.0           594.0  270  \n",
       "3             932.0           594.0  365  \n",
       "4             978.4           825.5  360  \n",
       "5             932.0           670.0   90  \n",
       "6             932.0           594.0  365  \n",
       "7             932.0           594.0   28  \n",
       "8             932.0           670.0   28  \n",
       "9             932.0           594.0   28  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Including all columns except Strength\n",
    "predictors = concrete_data.iloc[:, :-1]\n",
    "predictors.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb511b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    79.99\n",
       "1    61.89\n",
       "2    40.27\n",
       "3    41.05\n",
       "4    44.30\n",
       "5    47.03\n",
       "6    43.70\n",
       "7    36.45\n",
       "8    45.85\n",
       "9    39.29\n",
       "Name: Strength, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Only Strength Column\n",
    "target = concrete_data['Strength']\n",
    "target.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fa08ca",
   "metadata": {},
   "source": [
    "Let's save the number of predictors to n_cols since we will need this number when building our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2de70c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of predictors \n",
    "n_cols = predictors.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ab2ce4",
   "metadata": {},
   "source": [
    "Create a function that defines our regression model for us so that we can conveniently call it to create our model:\n",
    "\n",
    "- One hidden layer of 10 nodes, and a ReLU activation function\n",
    "- Use the adam optimizer and the mean squared error as the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1361dbb0",
   "metadata": {},
   "source": [
    "#### Build a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df271353",
   "metadata": {},
   "source": [
    "Let's define a function that defines our regression model for us so that we can conveniently call it to create our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "330ee324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define regression model\n",
    "\n",
    "def regression_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63dcec6",
   "metadata": {},
   "source": [
    "Build the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9647d65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = regression_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b19637",
   "metadata": {},
   "source": [
    "### Train and Test the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95658c6",
   "metadata": {},
   "source": [
    "Train and test the model at the same time using the fit-method. We will leave out 20% of the data for validation and we will train the model for 50 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51f82253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cycle value #1: mean_squared_error 226.87924194335938\n",
      "Cycle value #2: mean_squared_error 150.17823791503906\n",
      "Cycle value #3: mean_squared_error 131.70521545410156\n",
      "Cycle value #4: mean_squared_error 125.64649963378906\n",
      "Cycle value #5: mean_squared_error 119.2017593383789\n",
      "Cycle value #6: mean_squared_error 112.25725555419922\n",
      "Cycle value #7: mean_squared_error 96.59072875976562\n",
      "Cycle value #8: mean_squared_error 88.8746337890625\n",
      "Cycle value #9: mean_squared_error 76.23237609863281\n",
      "Cycle value #10: mean_squared_error 81.1646957397461\n",
      "Cycle value #11: mean_squared_error 70.36358642578125\n",
      "Cycle value #12: mean_squared_error 59.214073181152344\n",
      "Cycle value #13: mean_squared_error 55.94407272338867\n",
      "Cycle value #14: mean_squared_error 59.54146957397461\n",
      "Cycle value #15: mean_squared_error 57.24049377441406\n",
      "Cycle value #16: mean_squared_error 55.23329544067383\n",
      "Cycle value #17: mean_squared_error 61.243629455566406\n",
      "Cycle value #18: mean_squared_error 55.661773681640625\n",
      "Cycle value #19: mean_squared_error 52.29995346069336\n",
      "Cycle value #20: mean_squared_error 44.7680778503418\n",
      "Cycle value #21: mean_squared_error 46.34111404418945\n",
      "Cycle value #22: mean_squared_error 53.05040740966797\n",
      "Cycle value #23: mean_squared_error 55.73149871826172\n",
      "Cycle value #24: mean_squared_error 53.64201736450195\n",
      "Cycle value #25: mean_squared_error 58.608943939208984\n",
      "Cycle value #26: mean_squared_error 52.319610595703125\n",
      "Cycle value #27: mean_squared_error 51.349281311035156\n",
      "Cycle value #28: mean_squared_error 51.20306396484375\n",
      "Cycle value #29: mean_squared_error 53.076595306396484\n",
      "Cycle value #30: mean_squared_error 46.79199981689453\n",
      "Cycle value #31: mean_squared_error 55.098331451416016\n",
      "Cycle value #32: mean_squared_error 46.3205680847168\n",
      "Cycle value #33: mean_squared_error 39.54618453979492\n",
      "Cycle value #34: mean_squared_error 51.92222595214844\n",
      "Cycle value #35: mean_squared_error 46.17787170410156\n",
      "Cycle value #36: mean_squared_error 48.27700424194336\n",
      "Cycle value #37: mean_squared_error 52.500221252441406\n",
      "Cycle value #38: mean_squared_error 48.79982376098633\n",
      "Cycle value #39: mean_squared_error 44.31291580200195\n",
      "Cycle value #40: mean_squared_error 40.46333312988281\n",
      "Cycle value #41: mean_squared_error 50.93709182739258\n",
      "Cycle value #42: mean_squared_error 49.49990463256836\n",
      "Cycle value #43: mean_squared_error 42.189727783203125\n",
      "Cycle value #44: mean_squared_error 51.54576110839844\n",
      "Cycle value #45: mean_squared_error 48.35624313354492\n",
      "Cycle value #46: mean_squared_error 45.943477630615234\n",
      "Cycle value #47: mean_squared_error 49.00010681152344\n",
      "Cycle value #48: mean_squared_error 54.132659912109375\n",
      "Cycle value #49: mean_squared_error 47.92620849609375\n",
      "Cycle value #50: mean_squared_error 53.7178840637207\n"
     ]
    }
   ],
   "source": [
    "list_of_mean_squared_error = []\n",
    "for cycle in range(50):\n",
    "    #split the data into a training set (70%) and a test set (30%):  \n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors , target, test_size = 0.3)\n",
    "    #Train and test the model at the same time\n",
    "    res = model.fit(X_train, y_train, epochs=50, verbose=0, validation_data = ( X_test , y_test))\n",
    "    #Finding mean_squared_error as last value in history.\n",
    "    mean_squared_error = res.history['val_loss'][-1]\n",
    "    #Adding value of mean_squared_error for every cycle in list.\n",
    "    list_of_mean_squared_error.append(mean_squared_error)\n",
    "    print('Cycle value #{}: mean_squared_error {}'.format(cycle+1, mean_squared_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f6c493",
   "metadata": {},
   "source": [
    "Find the mean and the standard deviation of the mean squared errors:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4033176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the mean squared errors: 65.38046295166015\n",
      "The standard deviation of the mean squared errors: 33.8784517631442\n"
     ]
    }
   ],
   "source": [
    "print('The mean of the mean squared errors: {}'.format(np.mean(list_of_mean_squared_error)))\n",
    "print('The standard deviation of the mean squared errors: {}'.format(np.std(list_of_mean_squared_error)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c8acb6",
   "metadata": {},
   "source": [
    "## B. Normalize the data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b5e179",
   "metadata": {},
   "source": [
    "Repeat Part A but use a normalized version of the data. Recall that one way to normalize the data is by subtracting the mean from the individual predictors and dividing by the standard deviation.\n",
    "\n",
    "Normalize the data by substracting the mean and dividing by the standard deviation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9513313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>0.862735</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>1.055651</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>3.551340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>5.055221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.790075</td>\n",
       "      <td>0.678079</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>0.488555</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>0.070492</td>\n",
       "      <td>0.647569</td>\n",
       "      <td>4.976069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.145138</td>\n",
       "      <td>0.464818</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-1.291914</td>\n",
       "      <td>0.701883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.945704</td>\n",
       "      <td>0.244603</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>5.055221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.945704</td>\n",
       "      <td>0.244603</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.145138</td>\n",
       "      <td>0.464818</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-1.291914</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.854740</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cement  Blast Furnace Slag   Fly Ash     Water  Superplasticizer  \\\n",
       "0  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "1  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "2  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "3  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "4 -0.790075            0.678079 -0.846733  0.488555         -1.038638   \n",
       "5 -0.145138            0.464818 -0.846733  2.174405         -1.038638   \n",
       "6  0.945704            0.244603 -0.846733  2.174405         -1.038638   \n",
       "7  0.945704            0.244603 -0.846733  2.174405         -1.038638   \n",
       "8 -0.145138            0.464818 -0.846733  2.174405         -1.038638   \n",
       "9  1.854740           -0.856472 -0.846733  2.174405         -1.038638   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate       Age  \n",
       "0          0.862735       -1.217079 -0.279597  \n",
       "1          1.055651       -1.217079 -0.279597  \n",
       "2         -0.526262       -2.239829  3.551340  \n",
       "3         -0.526262       -2.239829  5.055221  \n",
       "4          0.070492        0.647569  4.976069  \n",
       "5         -0.526262       -1.291914  0.701883  \n",
       "6         -0.526262       -2.239829  5.055221  \n",
       "7         -0.526262       -2.239829 -0.279597  \n",
       "8         -0.526262       -1.291914 -0.279597  \n",
       "9         -0.526262       -2.239829 -0.279597  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors_norm = (predictors - predictors.mean()) / predictors.std()\n",
    "predictors_norm.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfd7301",
   "metadata": {},
   "source": [
    "Build the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18abbb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = predictors_norm.shape[1]\n",
    "def regression_model2():\n",
    "    model_2 = Sequential()\n",
    "    model_2.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model_2.add(Dense(1))\n",
    "    \n",
    "    model_2.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model_2\n",
    "\n",
    "model_2 = regression_model2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f06369",
   "metadata": {},
   "source": [
    "Train and test the model at the same time using the fit-method. We will leave out 30% of the data for validation and we will train the model for 50 epochs. And use predictors_norm instead of predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cea2373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cycle value #1: mean_squared_error 299.9188537597656\n",
      "Cycle value #2: mean_squared_error 151.49282836914062\n",
      "Cycle value #3: mean_squared_error 86.79348754882812\n",
      "Cycle value #4: mean_squared_error 87.87969207763672\n",
      "Cycle value #5: mean_squared_error 73.90184783935547\n",
      "Cycle value #6: mean_squared_error 73.05838775634766\n",
      "Cycle value #7: mean_squared_error 51.09978103637695\n",
      "Cycle value #8: mean_squared_error 45.27106857299805\n",
      "Cycle value #9: mean_squared_error 46.32917404174805\n",
      "Cycle value #10: mean_squared_error 45.99818420410156\n",
      "Cycle value #11: mean_squared_error 34.86263656616211\n",
      "Cycle value #12: mean_squared_error 40.047828674316406\n",
      "Cycle value #13: mean_squared_error 37.015106201171875\n",
      "Cycle value #14: mean_squared_error 36.02146911621094\n",
      "Cycle value #15: mean_squared_error 41.69187545776367\n",
      "Cycle value #16: mean_squared_error 35.21765899658203\n",
      "Cycle value #17: mean_squared_error 37.92621994018555\n",
      "Cycle value #18: mean_squared_error 27.262624740600586\n",
      "Cycle value #19: mean_squared_error 32.42148208618164\n",
      "Cycle value #20: mean_squared_error 29.62908935546875\n",
      "Cycle value #21: mean_squared_error 40.08666229248047\n",
      "Cycle value #22: mean_squared_error 32.96676254272461\n",
      "Cycle value #23: mean_squared_error 32.97341537475586\n",
      "Cycle value #24: mean_squared_error 36.592288970947266\n",
      "Cycle value #25: mean_squared_error 31.137704849243164\n",
      "Cycle value #26: mean_squared_error 34.46910095214844\n",
      "Cycle value #27: mean_squared_error 27.90599822998047\n",
      "Cycle value #28: mean_squared_error 26.456239700317383\n",
      "Cycle value #29: mean_squared_error 35.65093231201172\n",
      "Cycle value #30: mean_squared_error 30.72066307067871\n",
      "Cycle value #31: mean_squared_error 32.4315071105957\n",
      "Cycle value #32: mean_squared_error 36.2361946105957\n",
      "Cycle value #33: mean_squared_error 29.525774002075195\n",
      "Cycle value #34: mean_squared_error 30.81676483154297\n",
      "Cycle value #35: mean_squared_error 32.93411636352539\n",
      "Cycle value #36: mean_squared_error 31.542932510375977\n",
      "Cycle value #37: mean_squared_error 30.427001953125\n",
      "Cycle value #38: mean_squared_error 32.69411849975586\n",
      "Cycle value #39: mean_squared_error 28.625080108642578\n",
      "Cycle value #40: mean_squared_error 42.264278411865234\n",
      "Cycle value #41: mean_squared_error 29.241357803344727\n",
      "Cycle value #42: mean_squared_error 34.58136749267578\n",
      "Cycle value #43: mean_squared_error 27.99663734436035\n",
      "Cycle value #44: mean_squared_error 30.885517120361328\n",
      "Cycle value #45: mean_squared_error 26.164915084838867\n",
      "Cycle value #46: mean_squared_error 32.23526382446289\n",
      "Cycle value #47: mean_squared_error 35.54349136352539\n",
      "Cycle value #48: mean_squared_error 33.30142593383789\n",
      "Cycle value #49: mean_squared_error 32.558189392089844\n",
      "Cycle value #50: mean_squared_error 30.84150505065918\n"
     ]
    }
   ],
   "source": [
    "list_of_mean_squared_error = []\n",
    "for cycle in range(50):\n",
    "    #split the data into a training set (70%) and a test set (30%):  \n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.2)\n",
    "    #Train and test the model at the same time\n",
    "    res = model_2.fit(X_train, y_train, epochs=50, verbose=0, validation_data=(X_test, y_test))\n",
    "    #Finding mean_squared_error as last value in history.\n",
    "    mean_squared_error = res.history['val_loss'][-1]\n",
    "    #Adding value of mean_squared_error for every cycle in list.\n",
    "    list_of_mean_squared_error.append(mean_squared_error)\n",
    "    print('Cycle value #{}: mean_squared_error {}'.format(cycle+1, mean_squared_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fed8bb",
   "metadata": {},
   "source": [
    "Printing the mean and the standard deviation of the mean squared errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9717820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the mean squared errors: 45.67293006896973\n",
      "The standard deviation of the mean squared errors: 41.925601263682424\n"
     ]
    }
   ],
   "source": [
    "print('The mean of the mean squared errors: {}'.format(np.mean(list_of_mean_squared_error)))\n",
    "print('The standard deviation of the mean squared errors: {}'.format(np.std(list_of_mean_squared_error)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ea8acb",
   "metadata": {},
   "source": [
    "The mean squared errors in case B is less than in case A but the  Standard deviation of mean squared error in B is greater than A . And in my opinion it's not a very good idea to compare result of two poor neural networks with one hidden layer only. Data normalization does not help a lot. Error is huge for both cases: A and B.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafce0c1",
   "metadata": {},
   "source": [
    "## C. Increate the number of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7846b3f1",
   "metadata": {},
   "source": [
    "Repeat Part B but use 100 epochs this time for training.\n",
    "\n",
    "\n",
    "Train and test the model at the same time using the fit-method. We will leave out 30% of the data (data after normalization) for validation and we will train the model for 100 epochs instead of 50 epochs.\n",
    "\n",
    "Build the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd09c2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model3():\n",
    "    model_3 = Sequential()\n",
    "    model_3.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model_3.add(Dense(1))\n",
    "    \n",
    "    model_3.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model_3\n",
    "\n",
    "model_3 = regression_model3() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd40426f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cycle value #1: mean_squared_error 170.4151611328125\n",
      "Cycle value #2: mean_squared_error 91.01439666748047\n",
      "Cycle value #3: mean_squared_error 64.60135650634766\n",
      "Cycle value #4: mean_squared_error 45.29921340942383\n",
      "Cycle value #5: mean_squared_error 42.689517974853516\n",
      "Cycle value #6: mean_squared_error 44.542354583740234\n",
      "Cycle value #7: mean_squared_error 33.08058547973633\n",
      "Cycle value #8: mean_squared_error 36.49795913696289\n",
      "Cycle value #9: mean_squared_error 36.78158950805664\n",
      "Cycle value #10: mean_squared_error 36.93260955810547\n",
      "Cycle value #11: mean_squared_error 37.18305587768555\n",
      "Cycle value #12: mean_squared_error 38.11288833618164\n",
      "Cycle value #13: mean_squared_error 34.1373176574707\n",
      "Cycle value #14: mean_squared_error 40.264488220214844\n",
      "Cycle value #15: mean_squared_error 35.47918701171875\n",
      "Cycle value #16: mean_squared_error 38.60531234741211\n",
      "Cycle value #17: mean_squared_error 38.30622100830078\n",
      "Cycle value #18: mean_squared_error 36.383358001708984\n",
      "Cycle value #19: mean_squared_error 33.2047119140625\n",
      "Cycle value #20: mean_squared_error 39.425045013427734\n",
      "Cycle value #21: mean_squared_error 30.25882339477539\n",
      "Cycle value #22: mean_squared_error 35.81263732910156\n",
      "Cycle value #23: mean_squared_error 32.137794494628906\n",
      "Cycle value #24: mean_squared_error 34.53584289550781\n",
      "Cycle value #25: mean_squared_error 33.5889892578125\n",
      "Cycle value #26: mean_squared_error 32.96623611450195\n",
      "Cycle value #27: mean_squared_error 32.088436126708984\n",
      "Cycle value #28: mean_squared_error 43.70014953613281\n",
      "Cycle value #29: mean_squared_error 37.908836364746094\n",
      "Cycle value #30: mean_squared_error 36.04566192626953\n",
      "Cycle value #31: mean_squared_error 29.34229278564453\n",
      "Cycle value #32: mean_squared_error 32.68798065185547\n",
      "Cycle value #33: mean_squared_error 32.31875228881836\n",
      "Cycle value #34: mean_squared_error 31.421051025390625\n",
      "Cycle value #35: mean_squared_error 35.110923767089844\n",
      "Cycle value #36: mean_squared_error 35.00220489501953\n",
      "Cycle value #37: mean_squared_error 33.042327880859375\n",
      "Cycle value #38: mean_squared_error 35.79347610473633\n",
      "Cycle value #39: mean_squared_error 36.46181869506836\n",
      "Cycle value #40: mean_squared_error 31.202796936035156\n",
      "Cycle value #41: mean_squared_error 28.08837127685547\n",
      "Cycle value #42: mean_squared_error 25.787569046020508\n",
      "Cycle value #43: mean_squared_error 35.549346923828125\n",
      "Cycle value #44: mean_squared_error 36.528892517089844\n",
      "Cycle value #45: mean_squared_error 37.47837448120117\n",
      "Cycle value #46: mean_squared_error 36.34627151489258\n",
      "Cycle value #47: mean_squared_error 38.89242172241211\n",
      "Cycle value #48: mean_squared_error 32.14013671875\n",
      "Cycle value #49: mean_squared_error 29.270261764526367\n",
      "Cycle value #50: mean_squared_error 26.670696258544922\n"
     ]
    }
   ],
   "source": [
    "list_of_mean_squared_error = []\n",
    "for cycle in range(50):\n",
    "    # split the data into a training set (70%) and a test set (30%):  \n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.3)\n",
    "    #Train and test the model at the same time\n",
    "    res = model_3.fit(X_train, y_train, epochs=100, verbose=0, validation_data=(X_test, y_test))\n",
    "    #Finding mean_squared_error as last value in history.\n",
    "    mean_squared_error = res.history['val_loss'][-1]\n",
    "    #Adding value of mean_squared_error for every cycle in list.\n",
    "    list_of_mean_squared_error.append(mean_squared_error)\n",
    "    print('Cycle value #{}: mean_squared_error {}'.format(cycle+1, mean_squared_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a41cdc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the mean squared errors: 39.622714080810546\n",
      "The standard deviation of the mean squared errors: 21.034297887295477\n"
     ]
    }
   ],
   "source": [
    "print('The mean of the mean squared errors: {}'.format(np.mean(list_of_mean_squared_error)))\n",
    "print('The standard deviation of the mean squared errors: {}'.format(np.std(list_of_mean_squared_error)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d124ac74",
   "metadata": {},
   "source": [
    "The mean and the standard deviation of the mean squared errors in case B is bigger than in case C. But in both cases error is huge. In my opinion it's not a very good idea to compare result of two poor neural networks with one hidden layer only. Number of epoch does not help."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3875efcf",
   "metadata": {},
   "source": [
    "## D. Increase the number of hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac4020b",
   "metadata": {},
   "source": [
    "Repeat part B but use a neural network with the following instead:\n",
    "\n",
    "Three hidden layers, each of 10 nodes and ReLU activation function.\n",
    "How does the mean of the mean squared errors compare to that from Step B?\n",
    "\n",
    "Create a new model with three hidden layers, each of 10 nodes and ReLU activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e0c81cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model4():\n",
    "    model_4 = Sequential()\n",
    "    model_4.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model_4.add(Dense(10, activation='relu'))\n",
    "    model_4.add(Dense(10, activation='relu'))\n",
    "    model_4.add(Dense(1))\n",
    "    \n",
    "    model_4.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a543a01",
   "metadata": {},
   "source": [
    "Build a new model with 3 hidden layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8449f6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = regression_model4()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618f9457",
   "metadata": {},
   "source": [
    "Train and test the model at the same time using the fit-method. We will leave out 30% of the data (data after normalization) for validation and we will train the model for 50 epochs and use three hidden layers, each of 10 nodes and ReLU activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2146383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cycle value #1: mean_squared_error 141.2133331298828\n",
      "Cycle value #2: mean_squared_error 89.59857177734375\n",
      "Cycle value #3: mean_squared_error 63.706050872802734\n",
      "Cycle value #4: mean_squared_error 54.567657470703125\n",
      "Cycle value #5: mean_squared_error 40.03699493408203\n",
      "Cycle value #6: mean_squared_error 42.378448486328125\n",
      "Cycle value #7: mean_squared_error 36.78065490722656\n",
      "Cycle value #8: mean_squared_error 38.79425048828125\n",
      "Cycle value #9: mean_squared_error 36.01682662963867\n",
      "Cycle value #10: mean_squared_error 36.18518829345703\n",
      "Cycle value #11: mean_squared_error 34.868412017822266\n",
      "Cycle value #12: mean_squared_error 35.183067321777344\n",
      "Cycle value #13: mean_squared_error 33.62141799926758\n",
      "Cycle value #14: mean_squared_error 34.172393798828125\n",
      "Cycle value #15: mean_squared_error 28.52121353149414\n",
      "Cycle value #16: mean_squared_error 29.79411506652832\n",
      "Cycle value #17: mean_squared_error 31.706815719604492\n",
      "Cycle value #18: mean_squared_error 31.73746681213379\n",
      "Cycle value #19: mean_squared_error 34.934242248535156\n",
      "Cycle value #20: mean_squared_error 25.875167846679688\n",
      "Cycle value #21: mean_squared_error 28.21883773803711\n",
      "Cycle value #22: mean_squared_error 26.840465545654297\n",
      "Cycle value #23: mean_squared_error 27.091325759887695\n",
      "Cycle value #24: mean_squared_error 29.033740997314453\n",
      "Cycle value #25: mean_squared_error 27.350664138793945\n",
      "Cycle value #26: mean_squared_error 29.62208366394043\n",
      "Cycle value #27: mean_squared_error 25.16053581237793\n",
      "Cycle value #28: mean_squared_error 27.101621627807617\n",
      "Cycle value #29: mean_squared_error 24.26233673095703\n",
      "Cycle value #30: mean_squared_error 27.096969604492188\n",
      "Cycle value #31: mean_squared_error 26.26447868347168\n",
      "Cycle value #32: mean_squared_error 26.372541427612305\n",
      "Cycle value #33: mean_squared_error 24.908803939819336\n",
      "Cycle value #34: mean_squared_error 25.36152458190918\n",
      "Cycle value #35: mean_squared_error 22.855016708374023\n",
      "Cycle value #36: mean_squared_error 27.730127334594727\n",
      "Cycle value #37: mean_squared_error 25.12925148010254\n",
      "Cycle value #38: mean_squared_error 28.616226196289062\n",
      "Cycle value #39: mean_squared_error 24.95939826965332\n",
      "Cycle value #40: mean_squared_error 21.009607315063477\n",
      "Cycle value #41: mean_squared_error 26.538190841674805\n",
      "Cycle value #42: mean_squared_error 28.974533081054688\n",
      "Cycle value #43: mean_squared_error 22.097110748291016\n",
      "Cycle value #44: mean_squared_error 27.299468994140625\n",
      "Cycle value #45: mean_squared_error 21.544462203979492\n",
      "Cycle value #46: mean_squared_error 25.37823486328125\n",
      "Cycle value #47: mean_squared_error 22.694446563720703\n",
      "Cycle value #48: mean_squared_error 26.51432228088379\n",
      "Cycle value #49: mean_squared_error 26.03345489501953\n",
      "Cycle value #50: mean_squared_error 27.791603088378906\n"
     ]
    }
   ],
   "source": [
    "list_of_mean_squared_error = []\n",
    "for cycle in range(50):\n",
    "    #split the data into a training set (70%) and a test set (30%):  \n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.3)\n",
    "    #Train and test the model at the same time\n",
    "    res = model_4.fit(X_train, y_train, epochs=50, verbose=0, validation_data=(X_test, y_test))\n",
    "    #Finding mean_squared_error as last value in history.\n",
    "    mean_squared_error = res.history['val_loss'][-1]\n",
    "    #Adding value of mean_squared_error for every cycle in list.\n",
    "    list_of_mean_squared_error.append(mean_squared_error)\n",
    "    print('Cycle value #{}: mean_squared_error {}'.format(cycle+1, mean_squared_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f7fb54",
   "metadata": {},
   "source": [
    "Printing the mean and the standard deviation of the mean squared errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0aeac115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the mean squared errors: 33.59087348937988\n",
      "The standard deviation of the mean squared errors: 19.09187054852058\n"
     ]
    }
   ],
   "source": [
    "print('The mean of the mean squared errors: {}'.format(np.mean(list_of_mean_squared_error)))\n",
    "print('The standard deviation of the mean squared errors: {}'.format(np.std(list_of_mean_squared_error)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c261c1",
   "metadata": {},
   "source": [
    "The mean and the standard deviation of the mean squared errors in case D is less than in case A, B and C. And it's the only case where error is not very big. It means additional layers in neural network are more important than other things. Also it proves the comparison between poor neural network with one hidden layer in previous cases is a bad idea. Result can be unpredictable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
